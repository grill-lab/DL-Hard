

<!-- Title -->
<br />
<p align="center">
    <h1 align="center">DL-Hard</h1>
    <h2 align="center">Annotated Deep Learning Dataset For Passage and Document Retrieval</h2>

<!-- TABLE OF CONTENTS -->
<details open="open">
  <summary>Table of Contents</summary>
  <ol>
    <li><a href="#overview">Overview</a>
    <li><a href="#dataset">Dataset</a></li>
    <li><a href="#annotations">Annotations</a></li>
    <li><a href="#entity-links">Entity Links</a></li>
    <li><a href="#baselines">Baselines</a></li>
  </ol>
</details>

<!-- Overview -->
<h3 id="overview">Overview</h3>
<p> Deep Learning Hard (DL-HARD) is a new annotated dataset building upon standard deep learning benchmark evaluation datasets. It builds on TREC Deep Learning (DL) questions extensively annotated with query intent categories, answer types, wikified entities, topic categories, and result type metadata from a leading web search engine. Based on this data, we introduce a framework for identifying challenging questions. DL-HARD contains forty nine queries from the official 2019/2020 evaluation benchmark, half of which are newly and independently assessed. We perform experiments using the official submitted runs to DL on DL-HARD and find substantial differences in metrics and the ranking of participating systems. Overall, DL-HARD is a new resource that promotes research on neural ranking methods by focusing on challenging and complex queries. </p>

<!-- Dataset -->
<h3 id="dataset">Dataset</h3>
<p> XYZ </p>


<!-- Annotations -->
<h3 id="annotations">Annotations</h3>
<p> XYZ </p>

<!-- Entity Links -->
<h3 id="entity-links">Entity Links</h3>
<p> XYZ </p>

<!-- Baselines -->
<h3 id="baselines">Baselines</h3>
<p> XYZ </p>
